"""
Ground Truth Validation System - Bulletproof Medical Query Resolver
Validates answers against curated ground truth data then falls back to RAG retrieval.
"""

import json
import logging
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
import re
from dataclasses import dataclass
from enum import Enum
import os

logger = logging.getLogger(__name__)

class MatchConfidence(Enum):
    EXACT = 0.98
    HIGH = 0.85
    MEDIUM = 0.70
    LOW = 0.50

@dataclass
class GroundTruthMatch:
    question: str
    answer: str
    confidence: float
    source: str
    query_type: str
    document_source: str = ""
    
class GroundTruthValidator:
    """Validates queries against curated ground truth data with bulletproof precision."""
    
    def __init__(self, ground_truth_path: str = None):
        self.ground_truth_path = ground_truth_path or self._find_ground_truth_path()
        self.ground_truth_cache = {}
        self.medical_synonyms = {
            # Critical medical abbreviations
            'icp': ['intracranial pressure', 'ich', 'intracerebral hemorrhage', 'brain pressure'],
            'evd': ['external ventricular drain', 'ventricular drain', 'brain drain'],
            'ich': ['intracerebral hemorrhage', 'brain hemorrhage', 'intracranial bleeding', 'icp'],
            'sah': ['subarachnoid hemorrhage'],
            'tbi': ['traumatic brain injury', 'head injury'],
            'stemi': ['st elevation myocardial infarction', 'heart attack'],
            'sepsis': ['severe infection', 'septic shock', 'systemic infection'],
            'stroke': ['cerebrovascular accident', 'cva', 'brain attack'],
            'anaphylaxis': ['severe allergic reaction', 'allergic shock'],
            'asthma': ['bronchial asthma', 'respiratory distress'],
            
            # Medication mappings
            'epi': ['epinephrine', 'adrenaline', 'epipen'],
            'heparin': ['anticoagulant', 'blood thinner'],
            'nicardipine': ['calcium channel blocker', 'blood pressure medication'],
            'mannitol': ['osmotic diuretic', 'brain pressure medication'],
            'ativan': ['lorazepam', 'benzodiazepine'],
            
            # Procedure mappings
            'evd placement': ['ventricular drain insertion', 'brain drain placement'],
            'intubation': ['airway management', 'breathing tube'],
            'central line': ['central venous catheter', 'cvc'],
        }
        self._load_ground_truth_data()
    
    def _find_ground_truth_path(self) -> str:
        """Find ground truth directory in the project."""
        current_dir = Path(__file__).parent
        for _ in range(5):  # Search up to 5 levels up
            ground_truth_dir = current_dir / "ground_truth_qa"
            if ground_truth_dir.exists():
                return str(ground_truth_dir)
            current_dir = current_dir.parent
        
        # Fallback to relative path
        return "/Users/nimayh/Desktop/NH/V8/edbot-v8-fix-prp-44-comprehensive-code-quality/ground_truth_qa"
    
    def _load_ground_truth_data(self):
        """Load all ground truth data into memory for fast access."""
        if not os.path.exists(self.ground_truth_path):
            logger.error(f"Ground truth path not found: {self.ground_truth_path}")
            return
        
        logger.info(f"ðŸ” Loading ground truth data from: {self.ground_truth_path}")
        
        for category in ['protocols', 'guidelines', 'reference']:
            category_path = Path(self.ground_truth_path) / category
            if not category_path.exists():
                continue
                
            self.ground_truth_cache[category] = {}
            
            for json_file in category_path.glob("*.json"):
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    file_key = json_file.stem
                    self.ground_truth_cache[category][file_key] = data
                    
                except Exception as e:
                    logger.error(f"Failed to load {json_file}: {e}")
        
        total_files = sum(len(cat) for cat in self.ground_truth_cache.values())
        logger.info(f"âœ… Loaded {total_files} ground truth files")
    
    def validate_query(self, query: str) -> Optional[GroundTruthMatch]:
        """
        Validate query against ground truth data with bulletproof matching.
        Returns the best match or None if no confident match found.
        """
        query_lower = query.lower().strip()
        best_match = None
        best_confidence = 0.0
        
        # Step 1: Expand query with medical synonyms
        expanded_terms = self._expand_query_terms(query_lower)
        
        # Step 2: Search through all ground truth data
        for category, files_data in self.ground_truth_cache.items():
            for file_key, file_data in files_data.items():
                
                # Handle different JSON structures
                qa_pairs = self._extract_qa_pairs(file_data)
                
                for qa_item in qa_pairs:
                    confidence = self._calculate_match_confidence(
                        query_lower, expanded_terms, qa_item
                    )
                    
                    if confidence > best_confidence and confidence >= MatchConfidence.MEDIUM.value:
                        best_confidence = confidence
                        best_match = GroundTruthMatch(
                            question=qa_item.get('question', ''),
                            answer=qa_item.get('answer', ''),
                            confidence=confidence,
                            source=file_key,
                            query_type=category,
                            document_source=qa_item.get('source', file_key)
                        )
        
        if best_match and best_confidence >= MatchConfidence.MEDIUM.value:
            logger.info(f"ðŸŽ¯ Ground truth match found: {best_match.source} (confidence: {best_confidence:.2f})")
            return best_match
        
        return None
    
    def _expand_query_terms(self, query: str) -> List[str]:
        """Expand query with medical synonyms and abbreviations."""
        expanded = [query]
        
        for abbrev, synonyms in self.medical_synonyms.items():
            if abbrev in query:
                expanded.extend(synonyms)
                # Also expand the original query with synonyms
                for synonym in synonyms:
                    expanded.append(query.replace(abbrev, synonym))
        
        return list(set(expanded))
    
    def _extract_qa_pairs(self, file_data: Any) -> List[Dict]:
        """Extract Q&A pairs from different JSON structures."""
        qa_pairs = []
        
        # Handle list format (like EVD protocol)
        if isinstance(file_data, list):
            qa_pairs = file_data
        
        # Handle structured format with qa_pairs
        elif isinstance(file_data, dict) and 'qa_pairs' in file_data:
            qa_pairs = file_data['qa_pairs']
        
        # Handle flat dictionary format
        elif isinstance(file_data, dict):
            # Convert dict to qa format
            qa_pairs = [{
                'question': key,
                'answer': value,
                'source': file_data.get('document', 'ground_truth')
            } for key, value in file_data.items() 
            if key not in ['document', 'document_type', 'complexity']]
        
        return qa_pairs
    
    def _calculate_match_confidence(self, query: str, expanded_terms: List[str], qa_item: Dict) -> float:
        """Calculate confidence score for query-QA match with precise medical targeting."""
        question = qa_item.get('question', '').lower()
        answer = qa_item.get('answer', '').lower()
        
        if not question:
            return 0.0
        
        query_lower = query.lower()
        
        # PRIORITY 1: FORM QUERIES - Highest precision matching
        form_indicators = ['show me', 'form', 'consent', 'document', 'paperwork']
        is_form_query = any(indicator in query_lower for indicator in form_indicators)
        
        if is_form_query:
            # For form queries, require exact form-related matches
            form_terms = ['form', 'consent', 'document', 'transfusion', 'blood', 'pdf']
            has_form_content = any(term in question or term in answer for term in form_terms)
            
            if has_form_content:
                # Boost confidence for exact form matches
                if 'transfusion' in query_lower and 'transfusion' in (question + answer):
                    return MatchConfidence.EXACT.value
                elif 'blood' in query_lower and 'blood' in (question + answer):
                    return MatchConfidence.HIGH.value
                elif 'form' in query_lower and 'form' in (question + answer):
                    return MatchConfidence.HIGH.value
                else:
                    return MatchConfidence.MEDIUM.value
            else:
                # Severely penalize non-form content for form queries
                return 0.0
        
        # PRIORITY 2: MEDICAL PROTOCOL QUERIES - Existing precision logic
        if 'icp' in query_lower or 'ich' in query_lower or 'intracranial' in query_lower:
            # Only match with ICH/ICP specific protocols
            if any(term in question or term in answer for term in ['ich', 'intracranial', 'blood pressure', 'ventricular']):
                if 'retu' in question and 'ich' not in question:
                    return 0.0  # Avoid RETU pathways for ICP queries
                return MatchConfidence.HIGH.value
        
        if 'evd' in query_lower or 'external ventricular drain' in query_lower:
            if 'evd' in question or 'ventricular drain' in question:
                return MatchConfidence.HIGH.value
        
        if 'stemi' in query_lower:
            if 'stemi' in question or 'myocardial infarction' in question:
                return MatchConfidence.HIGH.value
            elif 'chf' in question or 'heart failure' in question:
                return 0.2  # Lower confidence for related but not exact matches
        
        if 'sepsis' in query_lower:
            if 'sepsis' in question or 'infection' in question:
                return MatchConfidence.HIGH.value
        
        if 'asthma' in query_lower:
            if 'asthma' in question or 'respiratory' in question:
                return MatchConfidence.HIGH.value
        
        if 'heparin' in query_lower or 'anticoagulant' in query_lower:
            if 'heparin' in question or 'anticoagulant' in question:
                return MatchConfidence.HIGH.value
        
        if 'epi' in query_lower and ('dosage' in query_lower or 'children' in query_lower):
            if 'epinephrine' in question and ('pediatric' in question or 'children' in question):
                return MatchConfidence.HIGH.value
        
        # Exact question match gets highest confidence
        if query_lower in question or question in query_lower:
            return MatchConfidence.EXACT.value
        
        # Calculate term overlap for general matching
        query_terms = set(self._extract_medical_terms(query_lower))
        question_terms = set(self._extract_medical_terms(question))
        answer_terms = set(self._extract_medical_terms(answer))
        
        # Check for critical medical term matches
        critical_matches = 0
        for term in query_terms:
            if term in question_terms or term in answer_terms:
                critical_matches += 1
            
            # Check synonyms
            for expanded_query in expanded_terms:
                expanded_terms_set = set(self._extract_medical_terms(expanded_query))
                if expanded_terms_set & (question_terms | answer_terms):
                    critical_matches += 1
                    break
        
        if len(query_terms) == 0:
            return 0.0
        
        base_confidence = critical_matches / len(query_terms)
        
        # PRECISION FILTER: Reject poor matches that might be misleading
        if base_confidence < 0.3:
            return 0.0
        
        # Boost confidence for specific matches
        if base_confidence >= 0.8:
            return MatchConfidence.MEDIUM.value  # Lower than exact matches
        elif base_confidence >= 0.6:
            return MatchConfidence.LOW.value
        else:
            return 0.0
    
    def _extract_medical_terms(self, text: str) -> List[str]:
        """Extract meaningful medical terms from text."""
        # Remove common stop words but keep medical terms
        stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'what', 'how', 'when', 'where', 'who', 'why'}
        
        # Extract alphanumeric terms
        terms = re.findall(r'\b[a-zA-Z][a-zA-Z0-9]*\b', text.lower())
        
        # Filter meaningful terms (length > 2 and not stop words)
        meaningful_terms = [term for term in terms 
                          if len(term) > 2 and term not in stop_words]
        
        return meaningful_terms
    
    def get_ground_truth_response(self, query: str) -> Optional[Dict[str, Any]]:
        """
        Get a complete response from ground truth data.
        Returns formatted response ready for API.
        """
        match = self.validate_query(query)
        
        if not match:
            return None
        
        # Format response based on query type
        response = self._format_ground_truth_response(match, query)
        
        return {
            "response": response,
            "sources": [{
                "display_name": match.document_source or match.source,
                "filename": f"{match.source}.pdf",
                "pdf_path": f"{match.source}.pdf"
            }],
            "confidence": match.confidence,
            "query_type": self._map_query_type(match.query_type),
            "has_real_content": True,
            "ground_truth_validated": True,
            "validation_source": match.source
        }
    
    def _format_ground_truth_response(self, match: GroundTruthMatch, original_query: str) -> str:
        """Format ground truth answer with proper medical formatting."""
        query_lower = original_query.lower()
        
        # Add appropriate medical context headers
        if 'icp' in query_lower or 'ich' in query_lower or 'intracranial' in query_lower:
            header = "ðŸ§  **ICP/ICH Management Protocol**\n\n"
        elif 'evd' in query_lower:
            header = "ðŸ”§ **External Ventricular Drain (EVD) Protocol**\n\n"
        elif 'stemi' in query_lower:
            header = "ðŸš¨ **STEMI Activation Protocol**\n\n"
        elif 'sepsis' in query_lower:
            header = "ðŸ¦  **ED Sepsis Protocol**\n\n"
        elif 'stroke' in query_lower:
            header = "âš¡ **Acute Stroke Protocol**\n\n"
        elif 'dosage' in query_lower or 'dose' in query_lower:
            header = "ðŸ’Š **Medication Dosing Guidelines**\n\n"
        else:
            header = "ðŸ“‹ **Medical Protocol Information**\n\n"
        
        # Format the answer with proper structure
        answer = match.answer
        
        # Add bullet points for lists if not already formatted
        if '\n' in answer and not answer.strip().startswith(('â€¢', '-', '*')):
            # Convert sentences to bullet points for better readability
            sentences = [s.strip() for s in answer.split('.') if s.strip()]
            if len(sentences) > 1:
                bullet_answer = '\n'.join([f"â€¢ {sentence}." for sentence in sentences if sentence])
                answer = bullet_answer
        
        formatted_response = f"{header}**Protocol Information:**\n{answer}"
        
        # Remove confidence disclaimers - keep responses clean and professional
        
        return formatted_response
    
    def _map_query_type(self, ground_truth_category: str) -> str:
        """Map ground truth category to API query type."""
        mapping = {
            'protocols': 'protocol',
            'guidelines': 'criteria', 
            'reference': 'summary'
        }
        return mapping.get(ground_truth_category, 'summary')

# Global instance for easy access
_ground_truth_validator = None

def get_ground_truth_validator() -> GroundTruthValidator:
    """Get singleton ground truth validator instance."""
    global _ground_truth_validator
    if _ground_truth_validator is None:
        _ground_truth_validator = GroundTruthValidator()
    return _ground_truth_validator

def validate_medical_query(query: str) -> Optional[Dict[str, Any]]:
    """
    Convenient function to validate a medical query against ground truth.
    Returns validated response or None.
    """
    validator = get_ground_truth_validator()
    return validator.get_ground_truth_response(query)